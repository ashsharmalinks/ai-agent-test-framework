{"name": "Query returns correct golden answer -- @1.1 ", "status": "broken", "statusDetails": {"message": "AttributeError: 'NoneType' object has no attribute 'json'\n", "trace": "  File \"C:\\Users\\asusv\\OneDrive\\Desktop\\ai-agent-test-framework\\.venv\\Lib\\site-packages\\behave\\model.py\", line 1991, in run\n    match.run(runner.context)\n    ~~~~~~~~~^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\asusv\\OneDrive\\Desktop\\ai-agent-test-framework\\.venv\\Lib\\site-packages\\behave\\matchers.py\", line 105, in run\n    self.func(context, *args, **kwargs)\n    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"features\\steps\\golden_steps.py\", line 7, in step_impl\n    answer = context.response.json()[\"text\"].strip()\n             ^^^^^^^^^^^^^^^^^^^^^\n"}, "steps": [{"name": "Given the API is available", "status": "passed", "start": 1755085185929, "stop": 1755085185932}, {"name": "When I ask \"What is 2+2?\"", "status": "passed", "start": 1755085185932, "stop": 1755085185936}, {"name": "Then the response should match \"4\"", "status": "broken", "statusDetails": {"message": "AttributeError: 'NoneType' object has no attribute 'json'\n", "trace": "  File \"C:\\Users\\asusv\\OneDrive\\Desktop\\ai-agent-test-framework\\.venv\\Lib\\site-packages\\behave\\model.py\", line 1991, in run\n    match.run(runner.context)\n    ~~~~~~~~~^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\asusv\\OneDrive\\Desktop\\ai-agent-test-framework\\.venv\\Lib\\site-packages\\behave\\matchers.py\", line 105, in run\n    self.func(context, *args, **kwargs)\n    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"features\\steps\\golden_steps.py\", line 7, in step_impl\n    answer = context.response.json()[\"text\"].strip()\n             ^^^^^^^^^^^^^^^^^^^^^\n"}, "start": 1755085185936, "stop": 1755085185938}], "parameters": [{"name": "query", "value": "What is 2+2?"}, {"name": "expected", "value": "4"}], "start": 1755085185928, "stop": 1755085185938, "uuid": "5f20f9e3-63a6-4ecc-a7bf-0b9f265211a4", "historyId": "b845e2a4b64bab6fa641e8b341253496", "fullName": "Golden Answer Validation: Query returns correct golden answer", "labels": [{"name": "severity", "value": "normal"}, {"name": "feature", "value": "Golden Answer Validation"}, {"name": "framework", "value": "behave"}, {"name": "language", "value": "cpython3"}], "titlePath": ["features", "Golden Answer Validation"]}